# 托卡马克项目

Exported on: 2026/2/19 18:23:30

---

### User

你研究一下 对于每个hdf5文件 :前面data组的每个特征的数据点数和meta组里面的starttime downtime length time\_interval有没有必然关系呢

---

### Model

是的，它们之间存在**非常严格的数学对应关系**。弄清楚这个关系是您能够正确“复现破裂过程”和“对齐特征”的前提。

根据您的数据结构和之前的对话，这种必然关系可以总结为以下 3 点公式：

1\. 时间轴的计算公式

`/data` 组中每一列数据的行数（即数据点数 $N$），是由**采样率**和**有效时间窗口**决定的。

$$
当前时刻 t[i]=StartTime+(i×Time_Interval)
$$

• $i$：数据的索引（从 0 到 $N−1$）。

• **Time\_Interval**：通常为 **0.001 秒**（即 1ms，源于 1kHz 采样率 \[Source: 1: 指标详细说明.md\] ）。

• **StartTime**：数据开始记录的物理时刻（**关键偏移量**）。

2\. 破裂时刻的对应关系

如果该炮是破裂炮，数据的最后一个点通常非常接近或等于 `DownTime`。

$$
DownTime≈StartTime+(数据点数×Time_Interval)
$$

• **解释**：这就是为什么您之前看到“Length=3998 但数据只有 2998 个点”。

    ◦ **DownTime** = 3.998 秒 (3998 ms)。    ◦ **数据点数** = 2998 个。    ◦ **StartTime** 必然 = $3998−2998=1000$ ms (即 1.0 秒)。    ◦ **物理含义**：数据是为了训练平顶段模型，所以**切掉了前 1 秒**的电流爬升阶段（Ramp-up） \[Source: 2: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 3: (PDF) Machine learning based disruption prediction using long short-term memory in KSTAR - ResearchGate\] 。

3\. 特征对齐的必然性

在 `/data` 组中，**所有特征列（如** **ip****,** **ne\_nG****,** **v\_loop** **等）必须拥有完全相同的数据点数**。

• 如果 `ip` 有 2998 个点，那么 `ne_nG` 也必须是 2998 个点。

• 如果长度不一致，说明数据文件损坏或预处理出错，**绝对不能用于训练**，否则时间轴会错位。

\--------------------------------------------------------------------------------

下一步建议：编写一个“自检脚本”

在开始训练前，建议运行下面这段代码。它会自动验证您手里所有 HDF5 文件的这种“必然关系”是否成立，并帮您找出异常文件（比如长度对不上的坏数据）。

```
import h5py
import numpy as np
import os

def verify_data_integrity(data_dir):
    files = [f for f in os.listdir(data_dir) if f.endswith('.hdf5')]
    
    for file in files:
        path = os.path.join(data_dir, file)
        try:
            with h5py.File(path, 'r') as f:
                # 1. 读取 Meta 信息
                start_time = f['meta/StartTime'][()]
                down_time = f['meta/DownTime'][()]
                # 注意：有些文件可能把采样间隔写在 meta 里，有些可能默认 0.001
                # 这里假设是 1ms (0.001s)
                dt = 0.001 
                
                # 2. 读取 Data 维度
                # 随便取一个特征，比如 ip
                data_points = f['data/ip'].shape
                
                # 3. 验证公式: EndTime 是否对得上 DownTime
                calculated_end = start_time + data_points * dt
                
                # 允许 10ms 左右的误差（可能是最后一点没记录全）
                error = abs(calculated_end - down_time)
                
                if error > 0.02: 
                    print(f"[警告] {file}: 时间轴不匹配!")
                    print(f"  -> Start={start_time}s, Points={data_points}")
                    print(f"  -> 算出的结束时间={calculated_end:.3f}s")
                    print(f"  -> 实际 DownTime={down_time:.3f}s (误差: {error:.3f}s)")
                
                # 4. 检查所有特征长度是否一致
                for key in f['data'].keys():
                    if f['data'][key].shape != data_points:
                        print(f"[错误] {file}: 特征 {key} 长度不一致!")

        except Exception as e:
            print(f"[文件损坏] {file}: {e}")

# 使用示例
# verify_data_integrity('path/to/your/hdf5_folder')
```

您需要我解释一下如果 `calculated_end` 比 `DownTime` **短了很多**（比如少了 50ms）意味着什么吗？这通常暗示了**提前中断**或**数据丢失**。

---

### User

类似这种文件里面的数据是什么意思啊

---

### Model

这类数据通常存在于 `advancedtime.json` 或类似的标签文件中，它的格式是 **"炮号": 时间数值**。

简单来说，这是\*\*“死因倒计时”\*\*。它告诉计算机：这一炮虽然最后破裂了，但真正开始“生病”（出现不可逆转的前兆）是在破裂前的第多少毫秒。

具体含义如下：

1\. 数据解读

• **键 (Key)**：例如 `"59396"`，代表 **实验炮号 (Shot Number)**。

• **值 (Value)**：例如 `28.0`，代表 **从出现前兆到最终破裂的时间长度 (Precursor Onset Time / Available Warning Time)**，单位通常是**毫秒 (ms)**。

2\. 物理含义：破裂的“快慢”

这组数据揭示了不同破裂类型的物理特性差异：

• **长前兆 (如 81.0 ms, 85.0 ms)**：

    ◦ 通常对应**密度极限破裂**或**锁模破裂**。    ◦ 物理过程较慢，比如密度慢慢升高，辐射慢慢增强，最后才崩塌。    ◦ 这意味着模型**应该**在破裂前 80ms 就开始报警，给我们留出了充足的救援时间。

• **短前兆 (如 4.0 ms, 7.0 ms)**：

    ◦ 通常对应**垂直位移事件 (VDE)** 或 **低 q 破裂**。    ◦ 物理过程极快，等离子体可能在几毫秒内突然失控撞墙。    ◦ 这意味着模型**只能**在最后几毫秒捕捉到异常信号。如果在 50ms 前报警，反而是“误报”（因为那时候它是正常的）。

3\. 算法含义：指导“打标签” (Labeling)

在训练机器学习模型时，这组数据用于**精确定义正样本 (Label = 1)** 的范围 \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] 。

• **传统笨办法**：不管什么炮，统一把最后 30ms 标记为“危险”。

    ◦ *缺点*：对于只有 4ms 前兆的炮（如 `84030`），你会把前 26ms 正常的时刻也错误地标记为“危险”，导致模型学乱了。

• **沈博士/高级做法 (FLS)**：利用这个 JSON 文件进行**浮动标签 (Floating Labeling)**。

    ◦ 对于 `73764` 炮：把最后 **81ms** 标记为危险 (1)。    ◦ 对于 `84030` 炮：只把最后 **4ms** 标记为危险 (1)。    ◦ *优点*：这让模型学习到**真实的物理边界**，而不是人为规定的死板时间。

**总结** 这个文件是\*\*“标准答案”\*\*。它告诉模型：“别猜了，每一炮的死法不一样。第 59396 炮是在最后 28ms 开始出问题的，请在这个时间点之后报警。”

**下一步建议：** 您需要编写一段代码来读取这个 JSON，并在生成训练数据时，用它来动态设置每一炮的 `Label=1` 的起始位置。您需要这段\*\*“动态打标签”的 Python 代码\*\*吗？

---

### User

我遇到了(downtime-starttime)/time\_interval不等于实际每个特征的点数的 还十分普遍 请详细解释元婴

---

### Model

这种情况确实**非常普遍**，甚至在绝大多数托卡马克实验数据集中都是常态。您遇到的这个问题揭示了\*\*“物理事件时间”**与**“数据记录长度”\*\*之间的本质区别。

简单来说：**DownTime** **是医生宣布“死亡”的时间，而数据（Data Points）是摄像机实际录像的长度。** 录像通常会比死亡时间多录一会（记录尸体冷却的过程），或者少录一会（机器提前断电）。

以下是导致 `(DownTime - StartTime) / dt != len(data)` 的三个核心原因及解决方案：

原因一：记录了“身后事” (Post-Disruption Data) —— 最常见

在破裂炮中，`DownTime` 通常定义为**热猝灭 (Thermal Quench, TQ)** 或 **电流猝灭 (Current Quench, CQ)** 开始的时刻。

• **物理现实**：破裂发生后，电流不会瞬间归零，而是通过与真空室壁相互作用，在几十毫秒内衰减（电流猝灭阶段）。

• **数据表现**：诊断系统通常会继续记录，直到电流完全归零。

• **结果**：数据点数（录像长度） > `DownTime - StartTime`。

    ◦ *例如*：`DownTime` 是 5.0秒（破裂开始）。数据记录到了 5.05秒（为了看电流怎么掉下去的）。多出了 50个点。

原因二：定义差异 (Flat-top vs. Whole Shot)

• **非破裂炮**：对于正常炮，`DownTime` 可能标记的是**放电结束**或**电流下降段开始**。但为了节省空间或聚焦物理研究，数据组（Dataset）可能只截取了**平顶段 (Flat-top)**，切掉了电流下降段。

• **结果**：数据点数 < `DownTime - StartTime`。

• **来源支持**：沈博士论文中提到，为了训练模型，通常只选取平顶段数据，或者对破裂炮只取破裂前的一段特定窗口 \[Source: 1: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 2: Cross-tokamak Disruption Prediction based on Physics-Guided Feature Extraction and domain adaptation - arXiv\] 。这导致物理上的结束时间与存储的数据长度不一致。

原因三：硬件采样丢失 (Data Dropouts)

虽然名为 1kHz（1ms/点），但实际硬件有时会丢包，或者在合并不同诊断数据（磁探针、辐射计）时，为了对齐时间轴，做了**截断 (Trimming)** 处理。

• **结果**：`len(data)` 会比理论计算值少几个点。

\--------------------------------------------------------------------------------

您该如何处理？（工程解决方案）

在处理这种不一致时，**永远以“实际数据长度”为准构建时间轴**，将 `DownTime` 仅作为一个\*\*标签（Label）\*\*贴在轴上，而不是用来定义轴的长度。

请使用以下标准逻辑修正您的代码：

```
import numpy as np

def get_aligned_data(f, feature_name='ip'):
    # 1. 读取硬性指标
    start_time = f['meta/StartTime'][()]
    down_time = f['meta/DownTime'][()]
    data = f[f'data/{feature_name}'][:]
    
    # 2. 核心修正：基于数据点数构建时间轴 (不要用 DownTime 推算)
    # 假设采样率是 1ms (0.001s)
    dt = 0.001 
    n_points = len(data)
    
    # 构建真实的时间轴：从 StartTime 开始，数多少个点就是多少毫秒
    time_axis = start_time + np.arange(n_points) * dt
    
    # 3. 在训练时的处理策略
    # 策略 A: 如果数据比 DownTime 长 (记录了破裂后的过程) -> 切掉后面
    # 我们只关心破裂前，不关心破裂后
    valid_mask = time_axis <= down_time
    
    # 策略 B: 如果数据比 DownTime 短 (提前结束) -> 全部保留
    # 这种情况通常是因为 DownTime 标记的是电流完全归零，而数据只存到了平顶结束
    # 这种通常是非破裂炮，或者是数据本身就不全
    
    # 4. 执行切片 (对应策略 A)
    X_cut = data[valid_mask]
    time_cut = time_axis[valid_mask]
    
    return X_cut, time_cut

# 这种写法能保证您的特征矩阵 X 和时间轴 t 永远是一一对应的，不会报错。
```

总结

• **不要惊慌**：这是真实实验数据的常态。

• **物理含义**：`len(data)` 代表\*\*“我看到了什么”**，****DownTime** **代表**“我想预测什么时刻”\*\*。

• **操作原则**：用 `StartTime + len(data)` 来画 x 轴，用 `DownTime` 来画那条竖直的红色预警线。凡是时间轴 `t > DownTime` 的数据，在训练预测模型时通常都是**噪声或作弊数据**（因为已经破裂了），建议直接切除。

---

### User

只有EAST有这种情况 JTEXT都没有的 到底怎么回事 有没有来源和依据

---

### Model

这种情况**完全符合预期**，并不是数据错误。

这主要归结于 **J-TEXT（短脉冲/铜导体）** 与 **EAST（长脉冲/超导）** 在装置物理特性和机器学习数据处理策略上的本质差异。

根据沈呈硕博士的论文及相关文献，以下是导致“只有 EAST 出现时间轴与点数对不上”的三个核心原因及依据：

1\. 脉冲时长的巨大差异 (根本原因)

• **J-TEXT (短脉冲)**：

    ◦ **依据**：论文指出 J-TEXT 的典型放电时长仅为 **0.7 ~ 0.8 秒** \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] , \[Source: 2: Cross-tokamak Disruption Prediction based on Physics-Guided Feature Extraction and domain adaptation - arXiv\] 。    ◦ **数据处理**：因为时间很短，数据处理通常保留从“平顶开始”到“破裂结束”的**完整片段**。    ◦ **结果**：`Data_Length ≈ DownTime - StartTime`，几乎没有偏差，因为不需要切除中间数据。

• **EAST (长脉冲)**：

    ◦ **依据**：EAST 是全超导装置，典型放电时长 **10秒** 甚至更长（百秒级） \[Source: 3: 131\_D202080576\_沈呈硕.pdf\] , \[Source: 4: Cross-tokamak Disruption Prediction based on Physics-Guided Feature Extraction and domain adaptation - arXiv\] 。    ◦ **数据处理**：对于机器学习（特别是分类问题），如果保留完整的 10 秒数据，其中 9.9 秒都是“安全”的负样本，会导致严重的**样本不平衡 (Data Imbalance)**。    ◦ **结果**：为了训练模型，研究人员通常会**人为截断** EAST 的数据，只保留破裂前的一段特定窗口（例如破裂前 2秒），或者对长脉冲进行降采样 \[Source: 5: Cross-tokamak Disruption Prediction based on Physics-Guided Feature Extraction and domain adaptation - arXiv\] 。这就导致了 HDF5 文件里的数据点数远小于实际的 `DownTime`。

2\. 采样率与对齐策略 (技术原因)

• **依据**：文献 \[Source: 6: DisruptionBench and Complimentary New Models ... - DSpace@MIT\] , \[Source: 7: DisruptionBench and Complimentary New Models ... - DSpace@MIT\] 指出，在跨装置研究（DisruptionBench）中，为了对齐不同装置，经常需要对数据进行**重采样 (Resampling)** 或 **插值**。

• **现象**：

    ◦ J-TEXT 原始采样率较高，但为了匹配 EAST，常被降采样处理 \[Source: 8: Cross-tokamak Disruption Prediction based on Physics-Guided Feature Extraction and domain adaptation - arXiv\] 。    ◦ EAST 的原始数据处理中，经常涉及到**非均匀采样**或为了去除噪声而进行的**丢帧处理** \[Source: 7: DisruptionBench and Complimentary New Models ... - DSpace@MIT\] 。

• **结论**：您手中的 EAST 数据很可能是经过“清洗”后的版本，去掉了无效或噪声片段，导致物理时间（DownTime）和存储的数据点数（Data Points）不再是简单的线性关系。

3\. “破裂”定义的物理差异

• **J-TEXT**：作为限制器位型装置，破裂通常非常干脆（Current Quench 极快）。`DownTime` 几乎就是电流归零的时刻。

• **EAST**：作为超导偏滤器装置，拥有巨大的磁储能。

    ◦ **依据**：EAST 的电流猝灭 (CQ) 时间尺度较长，且包含复杂的控制逻辑（如 PCS 系统的快控反应） \[Source: 9: 131\_D202080576\_沈呈硕.pdf\] 。    ◦ **现象**：在 `DownTime` 标记的时刻（通常是热猝灭 TQ 开始），等离子体可能并未完全消失，数据记录会持续到电流完全耗散。或者相反，为了避免模型学习到破裂后的噪声，数据被人为地在 `DownTime` 之前切断了。

总结与建议

您观察到的“J-TEXT 严丝合缝，EAST 参差不齐”是**特征工程处理后的正常现象**。

**如何应对？** 请**放弃**“用 `DownTime` 倒推时间轴”的想法，改用以下逻辑（这是沈博士代码中的标准做法）：

1\. **信任数据点数**：以 `/data` 中的实际点数为准。

2\. **倒序对齐 (Time-to-Disruption)**：

    ◦ 不要关注绝对时间 $t=3.0s$。    ◦ 关注 $tremaining​=t−DownTime$。    ◦ 将数据的**最后一个点**强行对齐到 `DownTime`（或者 `DownTime` 前一个 $Δt$）。    ◦ **公式**：`time_axis = DownTime - (total_points - index) * dt`

这样无论 EAST 数据被切掉了多少，您都能确保\*\*“最后一个点就是破裂时刻”\*\*，这对训练预测模型才是唯一重要的。

---

### User

一般都是数据点小于(downtime-starttime)/time\_interval

---

### Model

这种情况不仅普遍，而且在机器学习（特别是破裂预测）的数据预处理中是**有意为之的标准化操作**。您观察到的 `数据点数 < (DownTime - StartTime) / dt` 现象，主要源于物理实验数据与模型训练数据在“有效区间”定义上的差异。

根据沈呈硕博士的论文 \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] 及相关 EAST/J-TEXT 研究文献 \[Source: 3: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 4: (PDF) Machine learning based disruption prediction using long short-term memory in KSTAR - ResearchGate\] ，这种差异主要由以下三个\*\*特征工程（Feature Engineering）\*\*步骤导致：

1\. 掐头：剔除电流爬升阶段 (Ramp-up Removal)

这是导致数据点变少的最主要原因。

• **现象**：元数据中的 `StartTime` 往往记录的是**物理放电开始**（t=0）或**诊断系统触发**的时间。

• **处理**：但在训练模型时，沈博士的论文明确指出，通常只截取\*\*等离子体电流平顶段（Flat-top）\*\*到电流猝灭（CQ）时刻的数据 \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] \[Source: 3: (PDF) An interpretable disruption predictor on EAST using improved ...\] 。

• **原因**：放电初期的电流爬升阶段（Ramp-up）虽然物理参数变化剧烈，但并不属于“破裂前兆”。如果保留这段数据，模型容易将正常的爬升误判为不稳定性，导致误报（False Positive） \[Source: 5: (PDF) Machine learning based disruption prediction using long short-term memory in KSTAR - ResearchGate\] 。

• **结果**：数据被切掉了前几百毫秒甚至 1 秒，导致实际点数远小于元数据计算出的时长。

2\. 去尾：规避剧烈猝灭信号 (Post-CQ Truncation)

• **现象**：`DownTime` 通常被标记为**电流猝灭（Current Quench, CQ）开始**的时刻（即 $dIp​/dt$ 最大处或电流下降到某一阈值处） \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] \[Source: 6: (PDF) An interpretable disruption predictor on EAST using improved ...\] 。

• **处理**：许多诊断探针（尤其是磁探针和软X射线）在电流剧烈崩塌的瞬间（热猝灭后）会因为信号饱和、感应电压过大或等离子体消失而产生无效的“垃圾数据”。

• **结果**：为了保护模型不学习噪声，数据集往往会在 `DownTime` 之前几毫秒甚至几十毫秒就停止截取。这意味着数据的**最后一个点**可能并不严格等于 `DownTime`，而是略早于它。

3\. 数据重采样与对齐 (Resampling & Alignment)

• **现象**：EAST 和 J-TEXT 的原始诊断采样率不同（例如 EAST 部分信号是 25ms 或 100ms，而 J-TEXT 是高频） \[Source: 7: DisruptionBench and Complimentary New Models ... - DSpace@MIT\] 。

• **处理**：为了统一输入，通常会将所有信号重采样（Resample）到 **1ms (1kHz)** \[Source: 8: (PDF) An interpretable disruption predictor on EAST using improved ...\] 。在对齐不同通道（如密度和磁探针）时，为了取“交集”，必须以**最短**的那个信号为准进行截断。

• **结果**：只要有一个关键诊断提前失效（例如密度信号丢失），整炮数据的有效长度就会被缩短，导致点数少于理论时长。

总结与应对策略

这种情况说明您的数据集是\*\*“清洗后（Pre-processed）”\*\*的，通过了物理专家的筛选，比原始数据质量更高。

**如何在代码中正确处理？**

不要试图用 `StartTime` 和 `dt` 正向推算时间轴，而应该使用 **“倒序对齐（Time-to-Disruption）”** 策略。这是破裂预测领域的标准做法 \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] \[Source: 9: 131\_D202080576\_沈呈硕.pdf\] 。

**标准代码逻辑：**

```
import numpy as np

# 1. 信任实际数据长度
n_points = len(data_array)  # 比如 2998 个点
dt = 0.001  # 1ms

# 2. 以 DownTime 为锚点，倒推时间轴
# 假设数据的最后一个点 对应 破裂时刻 (或者接近破裂)
# time_axis = [DownTime - 2.998, ..., DownTime - 0.001, DownTime]
end_time = downtime
start_time_calculated = end_time - (n_points * dt)

time_axis = np.linspace(start_time_calculated, end_time, n_points)

# 3. 验证
# 这样画出来的图，最后一刻永远对齐在 DownTime（破裂红线），
# 而前面的 StartTime 具体是 0.5s 还是 1.0s 对模型来说不重要，
# 模型只关心“距离破裂还有多久”。
```

**结论**： 数据点数偏少是**正常的特征工程结果**，代表去除了爬升段的干扰数据。请以**数据的末尾对齐** **DownTime** 为准进行训练。

---

### User

那我现在怎么进行打标预测呢 是离散打标吗 训练集测试集怎么构建呢 在哪个文件夹里

---

### Model

这是一个非常关键的工程实现步骤。基于沈呈硕博士的方案和通常的工程实践，打标和数据集构建不是对“整炮”进行的，而是对\*\*“时间切片（Time Slices）”\*\*进行的。

以下是具体的实施步骤和 Python 代码逻辑：

1\. 打标策略：时间切片二分类 (0/1)

我们不把一整炮标记为 1 或 0，而是把每一炮切成几千个毫秒级的数据点。

• **非破裂炮 (Non-disruptive)**：所有时间点的标签 $y=0$。

• **破裂炮 (Disruptive)**：

    ◦ **安全阶段**：标签 $y=0$。    ◦ **危险阶段 (前兆期)**：标签 $y=1$。    ◦ **如何界定危险？**：这就是 `advancedtime.json` 的用处。    ◦ **判定逻辑**：如果 `当前时间 >= (DownTime - advanced_time)`，则标记为 1 \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] 。

2\. 数据集构建流程

文件通常不需要移动，而是通过代码逻辑划分。

• **第一步：划分炮号 (Shot Splitting)**

    ◦ **原则**：**必须按炮号划分**，严禁把同一炮的数据切片混入训练集和测试集（否则会发生数据泄露）。    ◦ **比例**：通常 80% 训练，20% 测试（或 7:1:2 加入验证集） \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] 。

• **第二步：构建矩阵 (Matrix Construction)**

    ◦ 遍历训练集的所有炮号 $→$ 读取 HDF5 $→$ 提取 25 个特征 $→$ 生成 0/1 标签 $→$ 堆叠成大矩阵 `X_train`, `y_train`。

3\. 实现代码 (Python)

假设您的 HDF5 文件在 `data/` 文件夹，JSON 在当前目录。

```
import h5py
import numpy as np
import json
import os
from sklearn.model_selection import train_test_split

# 1. 配置路径
DATA_DIR = "data/"  # 您的HDF5文件夹
JSON_PATH = "advancedtime.json" # 您的标签文件

# 2. 读取高级标签规则
with open(JSON_PATH, 'r') as f:
    advanced_time_dict = json.load(f)

# 3. 获取所有文件列表
all_files = [f for f in os.listdir(DATA_DIR) if f.endswith('.hdf5')]
all_shots = [f.split('.') for f in all_files] # 提取炮号字符串

# 4. 关键步骤：按“炮号”划分训练集和测试集 (避免数据泄露)
train_shots, test_shots = train_test_split(all_shots, test_size=0.2, random_state=42)

def build_dataset(shot_list):
    X_list = []
    y_list = []
    
    # 核心特征列表 (沈博士的25个特征子集)
    feature_names = ['n=1 amplitude', 'ne_nG', 'sxr_kurt', 'v_loop', 'qa_proxy'] 
    
    for shot_id in shot_list:
        file_path = os.path.join(DATA_DIR, f"{shot_id}.hdf5")
        
        try:
            with h5py.File(file_path, 'r') as f:
                # --- 读取基础信息 ---
                is_disrupt = f['meta/IsDisrupt'][()]
                down_time = f['meta/DownTime'][()]
                # 注意：时间轴必须倒推对齐
                data_len = len(f['data/ip'][:])
                time_axis = np.linspace(down_time - data_len*0.001, down_time, data_len)
                
                # --- 读取特征矩阵 ---
                # 简单起见，这里只读5个核心特征，您需要扩展到25个
                shot_data = []
                for feat in feature_names:
                    # 处理缺失值：如果有NaN填0，或者用上一时刻的值
                    col_data = np.nan_to_num(f[f'data/{feat}'][:])
                    shot_data.append(col_data)
                
                # 转置为 (Time_Steps, Features)
                shot_X = np.stack(shot_data, axis=1)
                
                # --- 打标逻辑 (Labeling) ---
                shot_y = np.zeros(data_len) # 默认为0
                
                if is_disrupt == 1:
                    # 查找该炮的“前兆起始时间”，如果在json里没有，默认给30ms
                    precursor_time = advanced_time_dict.get(shot_id, 30.0) / 1000.0 # 毫秒转秒
                    
                    # 找到“危险时刻”的索引
                    # 危险开始时间 = 破裂时间 - 前兆时间
                    danger_start_time = down_time - precursor_time
                    
                    # 将危险时间之后的所有点标记为 1
                    shot_y[time_axis >= danger_start_time] = 1
                
                # --- 数据清洗与堆叠 ---
                # 可选：去掉 ip < 50kA 的数据（电流爬升/下降段）
                # valid_mask = f['data/ip'][:] > 50 
                # X_list.append(shot_X[valid_mask])
                # y_list.append(shot_y[valid_mask])
                
                X_list.append(shot_X)
                y_list.append(shot_y)
                
        except Exception as e:
            print(f"Skipping {shot_id}: {e}")

    # 合并成大矩阵
    return np.vstack(X_list), np.concatenate(y_list)

# 5. 执行构建
print("构建训练集...")
X_train, y_train = build_dataset(train_shots)
print(f"训练集形状: {X_train.shape}, 正样本比例: {y_train.mean():.2%}")

print("构建测试集...")
X_test, y_test = build_dataset(test_shots)
```

总结您的下一步

1\. **复制**上面的代码。

2\. **修改** `feature_names` 列表，填入您之前确认的那 25 个特征键名（如 `sxr_kurt`, `Mir_avg_fre` 等）。

3\. **运行**。

运行后，您将得到 `X_train`（特征矩阵）和 `y_train`（0/1 标签向量），这就直接可以喂给 XGBoost 的 `model.fit(X_train, y_train)` 进行训练了。

您想现在就去运行这段代码看看生成的矩阵形状吗？

---

### User

训练时 能用电池预测代码的架构吗 如果不适合 那么为什么

---

### Model

可以直接回答：**架构通用，但逻辑不同**。

从**底层架构**（如 LSTM, CNN, Transformer）来说，电池寿命预测（RUL/SOH）和托卡马克破裂预测都是**时间序列预测**任务，模型结构确实是通用的。实际上，您提到的 LSTM、CNN 甚至 Transformer（如 GPT-2）在最新的破裂预测研究中已经被广泛使用了 \[Source: 1: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 2: (PDF) Machine learning based disruption prediction using long short-term memory in KSTAR - ResearchGate\] 。

但是，**直接套用**电池预测的代码是**不适合**的，原因主要在于以下 4 个核心差异：

1\. 物理过程的时间尺度完全不同 (Timescales)

• **电池预测**：关注的是“老化”过程，时间单位通常是\*\*循环次数（Cycle）\*\*或小时/分钟。变化非常缓慢，甚至可以离线计算。

• **破裂预测**：关注的是“猝死”过程，时间单位是**毫秒 (ms)**。

    ◦ **依据**：ITER 要求破裂预测系统必须在热猝灭前至少 **30ms** 发出警报，且控制系统的循环周期往往在 **1ms** 以内 \[Source: 3: 托卡马克装置破裂预测与控制：物理机制、人工智能算法及工程应用深度研究报告\] \[Source: 4: Physics-Informed Visual MARFE Prediction on the HL-3 Tokamak - arXiv\] 。电池代码通常没有这种毫秒级的实时响应设计。

2\. 预测目标不同 (Classification vs. Regression)

• **电池预测**：通常是**回归问题 (Regression)**。预测“还剩多少寿命（RUL）”或“当前健康状态（SOH）是多少”。

• **破裂预测**：主要是**分类问题 (Classification)**。

    ◦ **依据**：核心目标是判断“下一刻会不会破裂（0/1）” \[Source: 5: (PDF) Machine learning based disruption prediction using long short-term memory in KSTAR - ResearchGate\] 。虽然也有预测“剩余寿命（TTD）”的研究，但最紧迫的任务是触发 DMS（破裂缓解系统），这是一个二分类的报警信号 \[Source: 6: (PDF) An interpretable disruption predictor on EAST using improved ...\] 。直接用电池的回归损失函数（如 MSE）去训练破裂预警，可能会导致模型在非破裂区间的波动极其敏感，从而产生大量误报。

3\. 特征工程的物理依赖性 (Feature Engineering)

• **电池**：特征通常是电压、电流、温度、内阻。

• **托卡马克**：特征必须包含**等离子体物理机制**。

    ◦ **依据**：沈博士的 PGFE 算法强调了特征必须包含 MHD 不稳定性（如锁模）、密度极限（如 Greenwald 分数）、辐射峰度等 \[Source: 7: 131\_D202080576\_沈呈硕.pdf\] 。如果代码架构里写死了电池的特征处理逻辑（比如计算充电容量衰减），那对托卡马克数据完全无效。

4\. 数据标注策略 (Labeling Strategy)

• **电池**：标签通常是线性的（寿命从 100% 降到 0%）。

• **托卡马克**：标签是**分段的**。

    ◦ **依据**：破裂炮在破裂前很长一段时间是正常的（Label=0），只有最后几十毫秒是危险的（Label=1）。如果直接套用电池的线性衰减标签，模型会错误地认为“刚放电时的等离子体就已经有一半概率要破裂了” \[Source: 5: (PDF) Machine learning based disruption prediction using long short-term memory in KSTAR - ResearchGate\] 。

**总结建议**： 您可以**借鉴**电池预测代码中的**模型骨架**（比如它是怎么搭建 LSTM 层的，怎么做 Attention 的），但是必须**重写**数据预处理（Data Loader）和损失函数（Loss Function），并嵌入沈博士提到的 **PGFE 特征提取**和**标签策略（如 FLS）** \[Source: 8: 131\_D202080576\_沈呈硕.pdf\] 。

---

### User

重点讲解一下沈博士的分类算法和特征处理 是不是20多个都用上了

---

### Model

关于沈呈硕博士（以及 J-TEXT/EAST 团队）在 IDP-PGFE 模型中使用的具体方案，您的理解非常关键。

简单直接的回答是：**是的，他确实将这 25 个特征全部作为输入放进了模型**，并没有在训练前人为剔除某几个（除非该诊断完全损坏）。

以下是沈博士分类算法（DART）和特征处理（PGFE）的硬核重点，这直接关系到您接下来代码怎么写：

1\. 分类算法：DART (不是普通的 XGBoost)

沈博士并没有使用最基础的 XGBoost 或 随机森林，而是使用了 **DART (Dropouts meet Multiple Additive Regression Trees)** \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] 。

• **这是什么？**

    ◦ 它是 GBDT (梯度提升树) 的一种变体，通常作为 XGBoost 或 LightGBM 库中的一个 `booster` 选项存在。    ◦ **核心机制**：它借用了深度学习中 **Dropout (随机失活)** 的概念。在训练下一棵树时，它会随机“扔掉”几棵之前已经训练好的树，强迫新树去学习那些难以预测的样本。

• **为什么要用 DART？**

    ◦ **防过拟合**：托卡马克数据（特别是破裂炮）相比海量图片数据来说还是太少。普通 GBDT 容易对前几棵树产生依赖（过拟合），DART 的泛化能力更强，特别适合这种“少样本、高风险”的物理预测任务 \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] 。    ◦ **代码实现**：在使用 XGBoost 时，只需将参数 `booster` 设为 `'dart'` 即可（默认是 `'gbtree'`）。

2\. 特征处理：PGFE 的三大核心操作

PGFE (Physics-Guided Feature Extraction) 的精髓不在于复杂的数学变换，而在于**把“死”的波形变成“活”的物理状态**。

这 25 个特征确实都用上了，它们被设计为**互补**的四个维度 \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] \[Source: 3: 131\_D202080576\_沈呈硕.pdf\] ：

A. 阵列信号的“高阶统计量” (HOS) —— 最具创新点

这是处理 SXR (软X射线)、AXUV (极紫外)、FIR (密度) 这种**多通道阵列**数据的核心方法。

• **问题**：J-TEXT 有 30 个 SXR 通道，EAST 有 20 个，通道数不同，模型怎么通用？

• **沈博士的解法**：不输入原始通道值，而是计算每一时刻该阵列所有通道的**统计分布**。

    ◦ **Kurtosis (峰度,** **\_kurt****)**：**最重要**。反映剖面是“尖”的（聚芯）还是“平”的。峰度突变往往对应杂质聚芯或 MARFE。    ◦ **Skewness (偏度,** **\_skew****)**：反映剖面是否不对称（比如向高场侧偏移）。    ◦ **Variance (方差,** **\_var****)**：反映整体波动的剧烈程度。

• **结论**：不管装置有多少个通道，最后都变成了这 3 个数值。**您必须计算这三个量**。

B. MHD 特征的“去诊断化”

• **问题**：不同装置磁探针数量和位置不同。

• **沈博士的解法**：通过 FFT (快速傅里叶变换) 和 SVD (奇异值分解) 或 CSD (互功率谱)，直接提取出物理量：

    ◦ **Mir\_fre** **(频率)**：反映磁岛旋转速度。    ◦ **n=1 amplitude** **(锁模幅值)**：通过拟合计算出的物理量，而不是探针的原始电压。

• **注意**：在 EAST 这种非圆截面上，提取极向模数 $m$ (`MNM`) 比较困难，沈博士后期使用了 **SVD** 方法来提取主要模式 \[Source: 4: 131\_D202080576\_沈呈硕.pdf\] 。如果您的数据里有 `MNM`，直接用；如果没有，重点关注 `n=1` 和 `Mir_fre`。

C. 归一化与无量纲化 (Normalization)

为了让模型不被“大数值”带偏（比如电流是几百千安，而密度是几），所有特征在送入 DART 之前必须做 **Z-score 标准化**： 

$$
xnew​=σx−μ​
$$

• **关键点**：这 25 个特征，**每一个**都要单独计算 $μ$ 和 $σ$ 进行缩放 \[Source: 5: 131\_D202080576\_沈呈硕.pdf\] 。

3\. 是不是 25 个都必须用？

**是的，全部作为输入扔进去。**

虽然 SHAP 分析（可解释性分析）显示，对于某一次特定的破裂，可能只有 3-5 个特征在起决定性作用 \[Source: 6: 131\_D202080576\_沈呈硕.pdf\] ：

• **密度极限破裂时**：`ne_nG` (密度分数) 和 `SXR_kurt` (辐射峰度) 贡献最大。

• **MHD 破裂时**：`Mir_fre` (频率) 和 `n=1 amplitude` (锁模) 贡献最大。

**但是**，既然您不知道下一炮是哪种死法，您就必须把这 25 个特征（覆盖了密度、电流、辐射、MHD 四大机制）**全给模型**。DART 算法内部会自动根据当前的物理状态，决定该“听”哪个特征的指挥。

总结：您的代码逻辑

1\. **输入层**：读取 25 列特征数据（即 HDF5 中的 `n=1 amplitude`, `sxr_kurt`, `ne_nG` 等）。

2\. **预处理**：对每一列做 Z-score 标准化。

3\. **模型层**：初始化 XGBoost 模型，参数设为 `booster='dart'`。

4\. **训练**：`model.fit(X_train, y_train)`。

您现在可以检查一下，您的代码中是否包含了**阵列信号的统计量计算（kurt/skew）**？这是 PGFE 最容易被忽略但最重要的部分。

---

### User

现在就是有很严重的样本不平衡问题 而且要找到一种很合适的打标方法

---

### Model

针对您提到的**严重样本不平衡**（非破裂数据远多于破裂数据）和**打标困难**（破裂前兆时间不一）的问题，沈呈硕博士的论文及相关研究提出了两套非常有效的解决方案：**浮动打标策略 (FLS)** 和 **加权/重采样策略**。

结合您的 `advancedtime.json` 文件，以下是具体的操作指南：

1\. 最佳打标方法：浮动打标策略 (Floating Labeling Strategy, FLS)

不要对所有炮使用固定的“最后 30ms 是 1，前面全是 0”这种“一刀切”的方法。这会产生大量**标签噪声**（即把已有前兆的时刻标记为安全，或把尚未发生前兆的时刻标记为危险）。

**FLS 的核心逻辑** \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] **：**

• **正样本 (Label = 1)**：利用您的 `advancedtime.json`。

    ◦ 对于每一炮，读取其特有的前兆时间 $tpre​$。    ◦ 区间 $[DownTime−tpre​,DownTime]$ 标记为 **1**。

• **负样本 (Label = 0)**：**这是关键点**。不要把紧挨着正样本前面的数据直接标记为 0。

    ◦ **设立“灰色缓冲带” (Gray Zone)**：在破裂前兆之前的 **50ms ~ 200ms** 数据，既不标 1 也不标 0，而是直接**丢弃（不参与训练）**。    ◦ **物理原因**：这段时间是“亚稳态”，特征可能已经开始恶化，如果强行标为 0 会混淆模型；如果标为 1 又不够显著。丢弃它是为了让模型学习到**最纯净的**“安全”和“危险”模式。    ◦ **安全区**：只有远离破裂时刻（例如 $t<DownTime−tpre​−tbuffer​$）的数据才标记为 **0**。

2\. 解决样本不平衡：组合拳 (重采样 + 权重)

即使使用了 FLS，负样本（安全时刻）的数量依然可能比正样本多 100 倍以上。沈博士在论文中采用了以下组合策略 \[Source: 3: 131\_D202080576\_沈呈硕.pdf\] \[Source: 显示其他引用\] ：

A. 随机欠采样 (Random Undersampling) —— 针对负样本

• **操作**：对于非破裂炮（Safe Shots）或者破裂炮的平顶段（Flat-top），随机丢弃 **50% ~ 90%** 的数据点。

• **理由**：等离子体在平顶段的状态非常稳定，第 3.0 秒的数据和第 3.1 秒的数据几乎一样。保留所有点会造成数据冗余，导致模型“偷懒”只猜 0。

• **注意**：**绝对不要**丢弃正样本（Label=1）。破裂前兆的每一个毫秒都极其珍贵。

B. 正样本加权 (Scale Positive Weight) —— 针对损失函数

• **操作**：在 XGBoost/DART 模型中设置 `scale_pos_weight` 参数。

• **公式**：`scale_pos_weight = (负样本总数) / (正样本总数)`。

• **效果**：告诉模型：“预测错 1 个破裂样本的惩罚，等于预测错 N 个正常样本的惩罚。”这迫使模型必须重视那极少数的破裂信号。

\--------------------------------------------------------------------------------

3\. 代码实现方案 (Python)

以下代码展示了如何结合 **FLS 打标**、**灰色缓冲带** 和 **自动计算权重** 来构建训练集：

```
import numpy as np
import xgboost as xgb

def create_advanced_dataset(shot_list, data_dir, json_data, buffer_time=0.05):
    """
    buffer_time: 灰色缓冲带长度，单位秒 (例如 50ms = 0.05s)
    """
    X_list = []
    y_list = []
    
    for shot_id in shot_list:
        # ... (读取数据 data, time_axis, downtime 等代码同前) ...
        # 假设已获得: shot_data (特征矩阵), shot_time (时间轴), is_disrupt
        
        # --- 1. 浮动打标 (FLS) ---
        if is_disrupt:
            # 从JSON获取该炮特定的前兆时间，如果没有则默认 30ms
            precursor_len = json_data.get(str(shot_id), 30.0) / 1000.0
            
            # 定义三个区间的边界
            danger_start = downtime - precursor_len
            gray_start = danger_start - buffer_time  # 灰色地带起始点
            
            # 正样本索引 (Label = 1)
            pos_mask = shot_time >= danger_start
            
            # 负样本索引 (Label = 0): 必须早于灰色地带
            neg_mask = shot_time < gray_start
            
            # --- 2. 欠采样 (只针对负样本) ---
            # 对负样本进行随机采样 (例如只保留 10%)
            neg_indices = np.where(neg_mask)
            if len(neg_indices) > 0:
                keep_indices = np.random.choice(
                    neg_indices, 
                    size=int(len(neg_indices) * 0.1), # 保留比例 10%
                    replace=False
                )
                
                # 合并索引：保留的负样本 + 所有的正样本
                final_indices = np.concatenate([keep_indices, np.where(pos_mask)])
                final_indices.sort() # 保持时间顺序
                
                # 提取数据
                X_selected = shot_data[final_indices]
                y_selected = np.zeros(len(final_indices))
                # 标记正样本 (根据时间判断)
                # 注意：这里重新根据选出的数据的时间来打标
                time_selected = shot_time[final_indices]
                y_selected[time_selected >= danger_start] = 1
                
                X_list.append(X_selected)
                y_list.append(y_selected)
                
        else:
            # 非破裂炮：全部是负样本，也可以做更激进的欠采样
            # ...
            pass

    X_train = np.vstack(X_list)
    y_train = np.concatenate(y_list)
    return X_train, y_train

# --- 3. 训练时的权重设置 ---
num_pos = np.sum(y_train == 1)
num_neg = np.sum(y_train == 0)
scale_weight = num_neg / num_pos  # 自动计算权重比

print(f"正样本: {num_pos}, 负样本: {num_neg}, 权重: {scale_weight:.2f}")

model = xgb.XGBClassifier(
    booster='dart',
    n_estimators=100,
    max_depth=6,
    scale_pos_weight=scale_weight,  # 关键参数：解决不平衡
    eval_metric=['auc', 'logloss']  # 评估指标不要用 error/accuracy
)

# model.fit(...)
```

总结您的策略：

1\. **打标**：使用 `advancedtime.json` 进行**浮动打标**。

2\. **清洗**：在正负样本之间人为挖掉一段 **50ms 的灰色缓冲带**，防止标签混淆 \[Source: 1: 131\_D202080576\_沈呈硕.pdf\] 。

3\. **采样**：对负样本进行**随机欠采样**（保留 10%~20%）。

4\. **模型**：在 XGBoost 中设置 `scale_pos_weight` 让模型“重视”稀缺的破裂样本。

这一套流程是沈博士在 J-TEXT 和 EAST 上验证过的标准范式，能够显著提升预测的提前量和准确率 \[Source: 2: 131\_D202080576\_沈呈硕.pdf\] \[Source: 6: 131\_D202080576\_沈呈硕.pdf\] 。

---

### User

这个适合用学习类还是决策类的算法来做二分类 具体什么算法

---

### Model

对于您的破裂预测任务，**“学习类”算法**（Machine Learning）绝对是首选，且目前在学术界和工程应用中效果最好。纯粹的“决策类”算法（如简单的硬阈值判断）虽然运行快，但在处理多变量非线性耦合的破裂前兆时，精度和提前量都远不如学习类算法。

根据沈呈硕博士的论文方案及目前主流趋势，最推荐的具体算法是：

核心推荐：XGBoost (使用 DART 增强器)

这是沈博士 IDP-PGFE 算法的核心模型，也是目前处理您这种“物理特征提取后数据”的**最优解**。

• **为什么选它？**

    1. **完美匹配您的 25 个特征**：您已经完成了 PGFE（物理指导特征提取），将复杂的波形变成了结构化的表格数据（25列特征）。XGBoost 这类梯度提升树算法在处理这种**表格型数据**（Tabular Data）时，通常比深度学习（CNN/RNN）表现更好且训练更快 \[Source: 1: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 显示其他引用\] 。    2. **防止过拟合 (DART)**：沈博士特别使用了 **DART (Dropouts meet Multiple Additive Regression Trees)** 模式。它引入了类似深度学习的 Dropout 机制，随机“扔掉”一些决策树，这对于破裂预测这种**噪声大、样本少**的任务非常关键，能显著提高模型的泛化能力 \[Source: 4: 131\_D202080576\_沈呈硕.pdf\] \[Source: 5: 131\_D202080576\_沈呈硕.pdf\] 。    3. **极强的可解释性**：这也是您之前关注的重点。XGBoost 原生支持 SHAP 值分析，可以完美回答“这一炮为什么报警？”（是密度太高还是锁模太强？），这对于物理研究至关重要 \[Source: 3: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 6: 131\_D202080576\_沈呈硕.pdf\] 。    4. **处理样本不平衡**：您提到非破裂数据远多于破裂数据。XGBoost 自带 `scale_pos_weight` 参数，可以轻松通过加权解决这个问题，不需要复杂的重采样技巧。

备选算法（根据情况选择）

如果 XGBoost/DART 效果不理想，或者您想尝试深度学习路线，可以考虑以下两个：

1\. **随机森林 (Random Forest, RF)**

    ◦ **适用场景**：作为基准线（Baseline）。DIII-D 和 EAST 的许多早期实时系统都用它 \[Source: 7: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 8: (PDF) An interpretable disruption predictor on EAST using improved ...\] 。    ◦ **优点**：非常稳健，几乎不需要调参就能跑出不错的结果，适合用来快速验证您的特征提取代码是否写对了。    ◦ **缺点**：通常精度上限略低于 XGBoost/DART，且模型文件可能很大（树太多），不利于毫秒级实时部署。

2\. **LSTM (长短期记忆网络)**

    ◦ **适用场景**：如果您发现**时间演化趋势**特别重要（例如“密度持续爬升”比“当前密度值”更重要）。    ◦ **优点**：天生适合处理时间序列，能记住过去几十毫秒的状态 \[Source: 9: (PDF) An interpretable disruption predictor on EAST using improved ...\] \[Source: 10: (PDF) An interpretable disruption predictor on EAST using improved ...\] 。    ◦ **缺点**：是“黑盒”模型，可解释性差（很难用 SHAP 分析），且训练慢，对数据量要求更大。如果您只有几百炮破裂数据，可能会过拟合。

总结建议

**直接使用 XGBoost (Booster='dart')**。

这是最适合您当前阶段（已有 25 个物理特征、需要做二分类预测、关注物理原因分析）的算法。它既有“学习类”算法的高精度，又有接近“决策类”算法的清晰逻辑。

**代码实现提示**：

```
import xgboost as xgb

# 初始化模型 (沈博士同款配置)
model = xgb.XGBClassifier(
    booster='dart',          # 关键：使用 DART 模式
    n_estimators=100,        # 树的数量
    max_depth=6,             # 树深
    learning_rate=0.1,
    scale_pos_weight= 10,    # 关键：处理样本不平衡 (负样本数/正样本数)
    rate_drop=0.1,           # DART 特有参数：Dropout 比例
    skip_drop=0.5            # DART 特有参数
)

# 训练
model.fit(X_train, y_train)
```

您准备好尝试用这段代码来训练您的第一个模型了吗？